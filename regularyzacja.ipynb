{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d59f363",
   "metadata": {},
   "source": [
    "Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198431a4",
   "metadata": {},
   "source": [
    "Wczytanie zbioru danych, podział danych na testowe i treningowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7deb7c64",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2763470099.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [17]\u001b[1;36m\u001b[0m\n\u001b[1;33m    -O \"/tmp/cats-and-dogs.zip\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate\n",
    "\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
    "-O \"/tmp/cats-and-dogs.zip\"\n",
    "\n",
    "local_zip = '/tmp/cats-and-dogs.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "classes = ['Cat', 'Dog']\n",
    "original_cat = 'PetImages/Cat'\n",
    "original_dog = 'PetImages/Dog'\n",
    "original_cat = [name for name in os.listdir(os.path.join('PetImages/Cat'))]\n",
    "original_dog = [name for name in os.listdir(os.path.join('PetImages/Dog'))]\n",
    "random.seed(101)\n",
    "\n",
    "random.shuffle(original_cat)\n",
    "random.shuffle(original_dog)\n",
    "size = min(len(original_cat), len(original_dog))\n",
    "train_size = int(np.floor(0.7 * size))\n",
    "\n",
    "valid_size = int(np.floor(0.2 * size))\n",
    "test_size = size - train_size - valid_size\n",
    "base_directory = 'dataset'\n",
    "os.mkdir(base_directory)\n",
    "type_datasets = ['train', 'valid', 'test']\n",
    "directories = {}\n",
    "\n",
    "for type_dataset in type_datasets:\n",
    "    directory = os.path.join(base_directory, type_dataset)\n",
    "    os.mkdir(directory)\n",
    "    for name_class in classes:\n",
    "        animal = os.path.join(directory, name_class)\n",
    "        os.mkdir(animal)\n",
    "        directories[f'{type_dataset}_{name_class}'] = animal+'/'\n",
    "index = 0\n",
    "\n",
    "for name_cat, name_dog in zip(original_cat, original_dog):\n",
    "        if index <= train_size:\n",
    "            type_of_dataset = 'train'\n",
    "        elif train_size < index <= (train_size + valid_size):\n",
    "            type_of_dataset = 'valid'\n",
    "        elif (train_size + valid_size) < index <= (train_size + valid_size + test_size):\n",
    "            type_of_dataset = 'test'\n",
    "        shutil.copyfile(src=('PetImages/Cat/'+name_cat), dst=(directories[f'{type_of_dataset}_Cat']+name_cat))\n",
    "        shutil.copyfile(src=('PetImages/Dog/'+name_dog), dst=(directories[f'{type_of_dataset}_Dog']+name_dog))\n",
    "        index += 1\n",
    "\n",
    "print(f'Dog - train: {len(os.listdir(directories[\"train_Dog\"]))}\\tCat - train: {len(os.listdir(directories[\"train_Cat\"]))}')\n",
    "print(f'Dog - valid: {len(os.listdir(directories[\"valid_Dog\"]))}\\tCat - valid: {len(os.listdir(directories[\"valid_Cat\"]))}')\n",
    "print(f'Dog - test:  {len(os.listdir(directories[\"test_Dog\"]))}\\tCat - test:  {len(os.listdir(directories[\"test_Cat\"]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabaef1a",
   "metadata": {},
   "source": [
    "Wizualizacja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544bed65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'directories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n\u001b[0;32m      2\u001b[0m fig\u001b[38;5;241m.\u001b[39msubplots_adjust(hspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, wspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mdirectories\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_Cat\u001b[39m\u001b[38;5;124m\"\u001b[39m]))[:\u001b[38;5;241m8\u001b[39m]):\n\u001b[0;32m      4\u001b[0m     ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(directories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_Cat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39melement)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'directories' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (12, 12))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i, element in enumerate(os.listdir(os.path.join(directories[\"train_Cat\"]))[:8]):\n",
    "    ax = fig.add_subplot(4, 4, i+1)\n",
    "    img = Image.open(directories[\"train_Cat\"]+element)\n",
    "    ax.imshow(img)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for i, element in enumerate(os.listdir(os.path.join(directories[\"train_Dog\"]))[:8]):\n",
    "    ax = fig.add_subplot(4, 4, i+9)\n",
    "    img = Image.open(directories[\"train_Dog\"]+element)\n",
    "    ax.imshow(img)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df522759",
   "metadata": {},
   "source": [
    "Trenowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baab856b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m----> 6\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_size\u001b[49m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m      7\u001b[0m validation_steps \u001b[38;5;241m=\u001b[39m valid_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m      8\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_size' is not defined"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 150, 150\n",
    "train_data_dir = 'dataset/train/'\n",
    "validation_data_dir = 'dataset/valid/'\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "steps_per_epoch = train_size // batch_size\n",
    "validation_steps = valid_size // batch_size\n",
    "patience = 5\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        batch_size=batch_size, class_mode='binary')\n",
    "train_datagen_augmentation = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=30,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator_augmentation = train_datagen_augmentation.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a6293",
   "metadata": {},
   "source": [
    "Model podstawowy - Baseline, bez warstw splotowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204d584f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model_baseline\u001b[38;5;241m.\u001b[39madd(Flatten(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m3\u001b[39m)))\n\u001b[0;32m      3\u001b[0m model_baseline\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m model_baseline\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m----> 5\u001b[0m                        optimizer\u001b[38;5;241m=\u001b[39m\u001b[43moptimizers\u001b[49m\u001b[38;5;241m.\u001b[39mRMSprop(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m),\n\u001b[0;32m      6\u001b[0m                        metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m model_baseline\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "model_baseline = Sequential()\n",
    "model_baseline.add(Flatten(input_shape=(150, 150, 3)))\n",
    "model_baseline.add(Dense(units=1, activation='sigmoid'))\n",
    "model_baseline.compile(loss='binary_crossentropy',\n",
    "                       optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                       metrics=['accuracy'])\n",
    "model_baseline.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba71ec8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patience' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[43mpatience\u001b[49m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m history_baseline \u001b[38;5;241m=\u001b[39m model_baseline\u001b[38;5;241m.\u001b[39mfit_generator(train_generator,\n\u001b[0;32m      3\u001b[0m                                                 steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m      4\u001b[0m                                                 epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m      5\u001b[0m                                                 validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m      6\u001b[0m                                                 validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m      7\u001b[0m                                                 callbacks\u001b[38;5;241m=\u001b[39m[es])\n\u001b[0;32m      8\u001b[0m history_baseline_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history_baseline\u001b[38;5;241m.\u001b[39mhistory)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'patience' is not defined"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=patience, monitor='val_accuracy', restore_best_weights=True)\n",
    "history_baseline = model_baseline.fit_generator(train_generator,\n",
    "                                                steps_per_epoch=steps_per_epoch,\n",
    "                                                epochs=epochs,\n",
    "                                                validation_data=validation_generator,\n",
    "                                                validation_steps=validation_steps,\n",
    "                                                callbacks=[es])\n",
    "history_baseline_df = pd.DataFrame(history_baseline.history)\n",
    "history_baseline_csv_file = 'history/history_baseline.csv'\n",
    "with open(history_baseline_csv_file, mode='w') as f:\n",
    "    history_baseline_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ec682",
   "metadata": {},
   "source": [
    "Wyniki modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0e062a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m min_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      3\u001b[0m max_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodels\u001b[49m:\n\u001b[0;32m      6\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory/history_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "max_index = 0\n",
    "min_accuracy = 1\n",
    "max_loss = 0\n",
    "\n",
    "for model in models:\n",
    "    df = pd.read_csv(f'history/history_{model}.csv', index_col=0)\n",
    "    df.index += 1\n",
    "    if max_index < max(df.index):\n",
    "        max_index = max(df.index)\n",
    "    if min_accuracy > min(df[['accuracy', 'val_accuracy']].min()):\n",
    "        min_accuracy = min(df[['accuracy', 'val_accuracy']].min())\n",
    "    if max_loss < max(df[['loss', 'val_loss']].max()):\n",
    "        max_loss = max(df[['loss', 'val_loss']].max())\n",
    "for model in models:\n",
    "    df = pd.read_csv(f'history/history_{model}.csv', index_col=0)\n",
    "    df.index += 1\n",
    "    fig = plt.figure(figsize=(16,12))\n",
    "    ax = fig.add_subplot(211)\n",
    "    ax.plot(df['accuracy'], \"bp--\")\n",
    "    ax.plot(df['val_accuracy'], \"rp--\")\n",
    "    ax.set_title(f'Model {model} Accuracy', fontsize=20)\n",
    "    ax.set_ylabel('Accuracy', fontsize=15)\n",
    "    ax.set_xlabel('Epoch', fontsize=15)\n",
    "    ax.set_xlim([1, max_index])\n",
    "    ax.set_ylim([min_accuracy, 1])\n",
    "\n",
    "    for milestone in (0.7, 0.8, 0.9, 0.95):\n",
    "        ax.axhline(milestone, color=\"k\", linestyle=\"--\")\n",
    "        try:\n",
    "            if min(df[df['val_accuracy'] >= milestone].index) > 1:\n",
    "                plt.axvline(min(df[df['val_accuracy'] >= milestone].index), color=\"g\", linestyle=\"--\")\n",
    "                ax.text(min(df[df['val_accuracy'] >= milestone].index)+0.6, min_accuracy+0.02,\n",
    "                        f'Epoch: {min(df[df[\"val_accuracy\"] >= milestone].index)}', rotation=90)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "    ax = fig.add_subplot(212)\n",
    "    ax.plot(df['loss'], \"bp--\")\n",
    "    ax.plot(df['val_loss'], \"rp--\")\n",
    "    ax.set_title(f'Model {model} Loss', fontsize=20)\n",
    "    ax.set_ylabel('Loss', fontsize=15)\n",
    "    ax.set_xlabel('Epoch', fontsize=15)\n",
    "    ax.set_xlim([1, max_index])\n",
    "    ax.set_ylim([0, max_loss])\n",
    "    ax.legend(['Training', 'Validation'], loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'charts/train_history_{model}.png', transparent=True, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(16,12))\n",
    "ax = fig.add_subplot(211)\n",
    "for model, color in zip(models, colors):\n",
    "    df = pd.read_csv(f'history/history_{model}.csv', index_col=0)\n",
    "    df.index += 1\n",
    "    ax.plot(df['val_accuracy'], label=f'Model {model}', color=color, linewidth=3)\n",
    "    ax.axhline(df['val_accuracy'].max(), color=color, linestyle=\"dotted\", linewidth=4)\n",
    "\n",
    "ax.set_title(f'Accuracy', fontsize=20)\n",
    "ax.set_ylabel('Accuracy', fontsize=15)\n",
    "ax.set_xlabel('Epoch', fontsize=15)\n",
    "ax.set_xlim([1, max_index])\n",
    "ax.set_ylim([min_accuracy, 1])\n",
    "for milestone in (0.7, 0.8, 0.9, 0.95):\n",
    "    ax.axhline(milestone, color=\"k\", linestyle=\"--\")\n",
    "plt.legend(loc='lower right')\n",
    "ax = fig.add_subplot(212)\n",
    "for model, color in zip(models, colors):\n",
    "    df = pd.read_csv(f'history/history_{model}.csv', index_col=0)\n",
    "    df.index += 1\n",
    "    ax.plot(df['val_loss'], label=f'Model {model}', color=color, linewidth=3)\n",
    "    ax.axhline(df['val_loss'].min(), color=color, linestyle=\"dotted\", linewidth=4)\n",
    "ax.set_title(f'Loss', fontsize=20)\n",
    "ax.set_ylabel('Loss', fontsize=15)\n",
    "ax.set_xlabel('Epoch', fontsize=15)\n",
    "ax.set_xlim([1, max_index])\n",
    "ax.set_ylim([0, max_loss])\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'charts/train_history_of_each_model.png', transparent=True, dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c32be",
   "metadata": {},
   "source": [
    "Model sieci konwolucyjnej z jedną warstwą splotową oraz jedną warstwą łączącą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c23366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 10)      280       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 54760)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 54761     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,041\n",
      "Trainable params: 55,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_simple_1 = Sequential()\n",
    "model_simple_1.add(Conv2D(filters=10, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model_simple_1.add(MaxPooling2D(2, 2))\n",
    "model_simple_1.add(Flatten())\n",
    "model_simple_1.add(Dense(units=1, activation='sigmoid'))\n",
    "model_simple_1.compile(loss='binary_crossentropy',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])\n",
    "model_simple_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce7622",
   "metadata": {},
   "source": [
    "Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd36e96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_simple_1 \u001b[38;5;241m=\u001b[39m model_simple_1\u001b[38;5;241m.\u001b[39mfit_generator(\u001b[43mtrain_generator\u001b[49m,\n\u001b[0;32m      2\u001b[0m                                                 steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m      3\u001b[0m                                                 epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m      4\u001b[0m                                                 validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m      5\u001b[0m                                                 validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m      6\u001b[0m                                                 callbacks\u001b[38;5;241m=\u001b[39m[es])\n\u001b[0;32m      8\u001b[0m history_simple_1_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history_simple_1\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m      9\u001b[0m history_simple_1_csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory/history_simple_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "history_simple_1 = model_simple_1.fit_generator(train_generator,\n",
    "                                                steps_per_epoch=steps_per_epoch,\n",
    "                                                epochs=epochs,\n",
    "                                                validation_data=validation_generator,\n",
    "                                                validation_steps=validation_steps,\n",
    "                                                callbacks=[es])\n",
    "\n",
    "history_simple_1_df = pd.DataFrame(history_simple_1.history)\n",
    "history_simple_1_csv_file = 'history/history_simple_1.csv'\n",
    "with open(history_simple_1_csv_file, mode='w') as f:\n",
    "    history_simple_1_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf982fd",
   "metadata": {},
   "source": [
    "Model z dodatkowymi warstwami splotowymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c48561e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m model_1\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     31\u001b[0m model_1\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 32\u001b[0m model_1\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[43moptimizers\u001b[49m\u001b[38;5;241m.\u001b[39mRMSprop(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     33\u001b[0m model_1\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model_1.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(150,150,3)))\n",
    "model_1.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model_1.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model_1.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model_1.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model_1.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(256, activation='relu'))\n",
    "model_1.add(Dense(128, activation='relu'))\n",
    "model_1.add(Dense(units=1, activation='sigmoid'))\n",
    "model_1.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['accuracy'])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a01e2",
   "metadata": {},
   "source": [
    "Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cbd2473",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_simple_1 \u001b[38;5;241m=\u001b[39m model_simple_1\u001b[38;5;241m.\u001b[39mfit_generator(\u001b[43mtrain_generator\u001b[49m,\n\u001b[0;32m      2\u001b[0m                                                 steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m      3\u001b[0m                                                 epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m      4\u001b[0m                                                 validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[0;32m      5\u001b[0m                                                 validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m      6\u001b[0m                                                 callbacks\u001b[38;5;241m=\u001b[39m[es])\n\u001b[0;32m      8\u001b[0m history_simple_1_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history_simple_1\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m      9\u001b[0m history_simple_1_csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory/history_simple_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "history_simple_1 = model_simple_1.fit_generator(train_generator,\n",
    "                                                steps_per_epoch=steps_per_epoch,\n",
    "                                                epochs=epochs,\n",
    "                                                validation_data=validation_generator,\n",
    "                                                validation_steps=validation_steps,\n",
    "                                                callbacks=[es])\n",
    "\n",
    "history_simple_1_df = pd.DataFrame(history_simple_1.history)\n",
    "history_simple_1_csv_file = 'history/history_simple_1.csv'\n",
    "with open(history_simple_1_csv_file, mode='w') as f:\n",
    "    history_simple_1_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b383d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
